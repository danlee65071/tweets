{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-kq1yh2pV-Q",
        "outputId": "19d5ace5-a2c9-428b-cae2-65e3162f740f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.casual import casual_tokenize\n",
        "\n",
        "from gensim.parsing.preprocessing import preprocess_documents, preprocess_string\n",
        "from gensim.models.phrases import Phraser\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "dJZxxJXGwqW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_neg = pd.read_csv('data/processedNegative.csv').T\n",
        "df_neutral = pd.read_csv('data/processedNeutral.csv').T\n",
        "df_positive = pd.read_csv('data/processedPositive.csv').T"
      ],
      "metadata": {
        "id": "AVUdJNUbwnsH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_neg['sentiment'] = [-1 for i in range(df_neg.shape[0])]\n",
        "df_neutral['sentiment'] = [0 for i in range(df_neutral.shape[0])]\n",
        "df_positive['sentiment'] = [1 for i in range(df_positive.shape[0])]"
      ],
      "metadata": {
        "id": "469CNEebw4Zy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Join data"
      ],
      "metadata": {
        "id": "B-hq5kCpznq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_neg, df_neutral, df_positive]).reset_index()\n",
        "df.rename(columns={'index': 'text'}, inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tkWX3gQGx0Zo",
        "outputId": "f06e827e-ea65-47a4-b9fb-faa00987110a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  sentiment\n",
              "0                 How unhappy  some dogs like it though         -1\n",
              "1     talking to my over driver about where I'm goin...         -1\n",
              "2     Does anybody know if the Rand's likely to fall...         -1\n",
              "3            I miss going to gigs in Liverpool unhappy          -1\n",
              "4         There isnt a new Riverdale tonight ? unhappy          -1\n",
              "...                                                 ...        ...\n",
              "3868  Thanks for the recent follow Happy to connect ...          1\n",
              "3869              - top engaged members this week happy          1\n",
              "3870  ngam to  weeks left for cadet pilot exam cryin...          1\n",
              "3871            Great! You're welcome Josh happy  ^Adam          1\n",
              "3872  Sixth spot not applicable Team! Higher pa! :)K...          1\n",
              "\n",
              "[3873 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f410f140-16b0-4f84-a9a1-7d541ff30a95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How unhappy  some dogs like it though</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talking to my over driver about where I'm goin...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Does anybody know if the Rand's likely to fall...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I miss going to gigs in Liverpool unhappy</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>There isnt a new Riverdale tonight ? unhappy</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3868</th>\n",
              "      <td>Thanks for the recent follow Happy to connect ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3869</th>\n",
              "      <td>- top engaged members this week happy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3870</th>\n",
              "      <td>ngam to  weeks left for cadet pilot exam cryin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3871</th>\n",
              "      <td>Great! You're welcome Josh happy  ^Adam</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3872</th>\n",
              "      <td>Sixth spot not applicable Team! Higher pa! :)K...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3873 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f410f140-16b0-4f84-a9a1-7d541ff30a95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f410f140-16b0-4f84-a9a1-7d541ff30a95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f410f140-16b0-4f84-a9a1-7d541ff30a95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Look at data in graph"
      ],
      "metadata": {
        "id": "qFeu9Rtc0Uvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_negative = df_neg.shape[0]\n",
        "num_neutral = df_neutral.shape[0]\n",
        "num_positive = df_positive.shape[0]\n",
        "plt.pie([num_negative, num_neutral, num_positive], labels=['negative', 'neutral', 'positive'], autopct='%.0f%%')\n",
        "None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "AaQrH9Fo0Y8F",
        "outputId": "a81a5470-e774-4a41-8584-2cf7aeb466fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Top 10 similar"
      ],
      "metadata": {
        "id": "PuFXl2WAZUCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(vec1, vec2):\n",
        "  dot_prod = 0\n",
        "  for i, v in enumerate(vec1):\n",
        "    dot_prod += v * vec2[i]\n",
        "  mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
        "  mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
        "  return dot_prod / (mag_1 * mag_2)\n",
        "\n",
        "\n",
        "def top10(data_vectors, tweet_id):\n",
        "  vec1 = data_vectors[tweet_id]\n",
        "  cosines = []\n",
        "  for id, vector in enumerate(data_vectors):\n",
        "    if tweet_id != id:\n",
        "      cosines.append({'id': id, 'val': cosine_sim(vec1, vector)})\n",
        "  res = sorted(cosines, key=lambda d: d['val'], reverse=True)\n",
        "  return res[:10]"
      ],
      "metadata": {
        "id": "Wdv2O6nOZXox"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Just tokenization"
      ],
      "metadata": {
        "id": "G9osQlLP0Gru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_doc(doc):\n",
        "  return [casual_tokenize(text) for text in doc]\n",
        "\n",
        "def normalization(tokenize_doc):\n",
        "  return [[token.lower() for token in tokens] for tokens in tokenize_doc]\n",
        "\n",
        "def remove_stopwords(tokenize_doc):\n",
        "  stop_words = stopwords.words('english')\n",
        "  return [[token for token in tokens if token not in stop_words] for tokens in tokenize_doc]\n",
        "\n",
        "def make_bigrams(tokenize_doc):\n",
        "  bigrams_phrases = Phrases(tokenize_doc)\n",
        "  bigram = Phraser(bigrams_phrases)\n",
        "  doc_bigram = [bigram[text] for text in tokenize_doc]\n",
        "  return doc_bigram\n",
        "\n",
        "FILTERS = [tokenize_doc, normalization, remove_stopwords, make_bigrams]\n",
        "\n",
        "def preprocessing_doc(doc, filters=FILTERS):\n",
        "  for f in filters:\n",
        "    doc = f(doc)\n",
        "  return doc"
      ],
      "metadata": {
        "id": "hrpJKJccjWR5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot"
      ],
      "metadata": {
        "id": "7ArtB8sbvjOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_vectorize(doc):\n",
        "  doc_seq = preprocessing_doc(doc)\n",
        "  vocab = set()\n",
        "  for token_seq in doc_seq:\n",
        "    for word in token_seq:\n",
        "      vocab.add(word)\n",
        "  vocab = sorted(vocab)\n",
        "  vocab_size = len(vocab)\n",
        "  onehot_vectors = np.zeros((len(doc), vocab_size), int)\n",
        "  for token_sequence in doc_seq:\n",
        "    for i, word in enumerate(token_sequence):\n",
        "      onehot_vectors[i, vocab.index(word)] = 1\n",
        "  return onehot_vectors\n"
      ],
      "metadata": {
        "id": "2deux_UCvHsU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data on test and train parts "
      ],
      "metadata": {
        "id": "Gy4mq37xAJBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_onehot = onehot_vectorize(df['text'])\n",
        "X_train_onehot, X_test_onehot, y_train, y_test = train_test_split(df_onehot, df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])"
      ],
      "metadata": {
        "id": "bjA0nzfQAQcr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "HuiIS3r51l0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "MNB_onehot = MultinomialNB()\n",
        "MNB_onehot.fit(X_train_onehot, y_train)\n",
        "mnb_onehot_pred = MNB_onehot.predict(X_test_onehot)\n",
        "print(f'accuracy: {accuracy_score(y_test, mnb_onehot_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oT5DqeQ2YyT",
        "outputId": "d6446c80-db10-4de5-cce2-d4f23718edc5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.40903225806451615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "iLa7BFD-Cg8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "KNN_onehot = KNeighborsClassifier()\n",
        "KNN_onehot.fit(X_train_onehot, y_train)\n",
        "KNN_onehot_pred = KNN_onehot.predict(X_test_onehot)\n",
        "print(f'accuracy: {accuracy_score(y_test, KNN_onehot_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXWmUSYYCj6p",
        "outputId": "8d42af0c-1b52-4667-d188-ac2bef38a052"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.40903225806451615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest"
      ],
      "metadata": {
        "id": "NErtxbkHDPWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF_onehot = RandomForestClassifier()\n",
        "RF_onehot.fit(X_train_onehot, y_train)\n",
        "RF_onehot_pred = RF_onehot.predict(X_test_onehot)\n",
        "print(f'accuracy: {accuracy_score(y_test, RF_onehot_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "karz5NHlDO1d",
        "outputId": "54108e4e-cf11-4ce8-b60a-5fa00ef6ea7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.4129032258064516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgT3rI3Zcxv4",
        "outputId": "70c05481-e6a2-4627-9c7b-2a4b0ca64977"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How unhappy  some dogs like it though\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_sim = top10(df_onehot, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYeKnLSldAtH",
        "outputId": "143531e4-e011-4116-e787-20244414b878"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for top in top_sim:\n",
        "  print(df['text'][top['id']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppy1WZRceIH4",
        "outputId": "79a2eb60-d5c5-4685-d493-3935b632bf43"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does anybody know if the Rand's likely to fall against the dollar? I got some money  I need to change into R but it keeps getting stronger unhappy \n",
            "I miss going to gigs in Liverpool unhappy \n",
            "talking to my over driver about where I'm goinghe said he'd love to go to New York too but since Trump it's probably not\n",
            "Who's that chair you're sitting in? Is this how I find out. Everyone knows now. You've shamed me in pu\n",
            "How unhappy  some dogs like it though\n",
            "There isnt a new Riverdale tonight ? unhappy \n",
            "don't like how jittery caffeine makes me sad \n",
            "My area's not on the list unhappy  think I'll go LibDems anyway\n",
            "I want fun plans this weekend unhappy \n",
            "When can you notice me.  unhappy  what?  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word counts"
      ],
      "metadata": {
        "id": "GErimVGDE1Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "bags_of_words = []\n",
        "tokenize_doc = preprocessing_doc(df['text'])\n",
        "for text in tokenize_doc:\n",
        "  bags_of_words.append(Counter(text))\n",
        "df_bows = pd.DataFrame.from_records(bags_of_words).fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "FGCLwNlQE6Rq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data"
      ],
      "metadata": {
        "id": "ot3pVOPjGaNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_count, X_test_count, y_train, y_test = train_test_split(df_bows, df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])"
      ],
      "metadata": {
        "id": "-kMtHW4uGeqS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Byes"
      ],
      "metadata": {
        "id": "7MYoJIXxG1F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MNB_count = MultinomialNB()\n",
        "MNB_count.fit(X_train_count, y_train)\n",
        "MNB_count_pred = MNB_count.predict(X_test_count)\n",
        "print(f'accuracy: {accuracy_score(y_test, MNB_count_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4ShFcR9G6AX",
        "outputId": "b5c8943e-28ad-4793-ec9b-c172bad1e5ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8941935483870967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "MP6IX5x3HTyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KNN_count = KNeighborsClassifier()\n",
        "KNN_count.fit(X_train_count, y_train)\n",
        "KNN_count_pred = KNN_count.predict(X_test_count)\n",
        "print(f'accuracy: {accuracy_score(y_test, KNN_count_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd4tK821HWQQ",
        "outputId": "801d0538-e21b-47b9-edfb-10f86da4b652"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8258064516129032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest"
      ],
      "metadata": {
        "id": "Gg0uMqCuHp21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF_count = RandomForestClassifier()\n",
        "RF_count.fit(X_train_count, y_train)\n",
        "RF_count_pred = RF_count.predict(X_test_count)\n",
        "print(f'accuracy: {accuracy_score(y_test, RF_count_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97h_gHCzHtR3",
        "outputId": "3b9f8523-5d14-4a99-8e1a-635c3b2598c9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9019354838709678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_sim = top10(df_bows.to_numpy(), 5)\n",
        "for top in top_sim:\n",
        "  print(df['text'][top['id']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCUwU9iLkERM",
        "outputId": "92d6fb2f-dd63-400b-f063-e3064fd03e50"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GO AWAY unhappy  \n",
            "even me unhappy  *hugs*\n",
            "Someone messed up unhappy  Available**\n",
            "Don't do that unhappy \n",
            "Same unhappy \n",
            "same unhappy \n",
            " same unhappy \n",
            "how about me unhappy \n",
            "same unhappy  \n",
            "now i don%27t want to go camp unhappy \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "qYebUh5ZIXZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "FlvW-DpnIcYh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [' '.join(t) for t in preprocess_documents(df['text'])]"
      ],
      "metadata": {
        "id": "bNykZoSbqLyl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF vectorizer"
      ],
      "metadata": {
        "id": "nZWdHyXkrGGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = CountVectorizer()\n",
        "tfidf = TfidfTransformer()\n",
        "word_count = counter.fit_transform(text)\n",
        "tfidf_text = tfidf.fit_transform(word_count)"
      ],
      "metadata": {
        "id": "jLPXLEmfpfhj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data"
      ],
      "metadata": {
        "id": "5eg-moGQpmrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(tfidf_text, df['sentiment'], random_state=42, test_size=0.2, stratify=df['sentiment'])"
      ],
      "metadata": {
        "id": "tCdNyY2VplZQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "W2WTrScVt4cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MNB_tfidf = MultinomialNB()\n",
        "MNB_tfidf.fit(X_train_tfidf, y_train)\n",
        "MNB_tfidf_pred = MNB_tfidf.predict(X_test_tfidf)\n",
        "print(f'accuracy: {accuracy_score(y_test, MNB_tfidf_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8jLDjxsrZi5",
        "outputId": "020721de-b75b-4b59-cf84-9088abbaee31"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8735483870967742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "hkmjVS_IuWWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KNN_tfidf = KNeighborsClassifier()\n",
        "KNN_tfidf.fit(X_train_tfidf, y_train)\n",
        "KNN_tfidf_pred = KNN_tfidf.predict(X_test_tfidf)\n",
        "print(f'accuracy: {accuracy_score(y_test, KNN_tfidf_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE1Anv-Brelw",
        "outputId": "6acda234-93a6-4460-bd9b-17b67650602e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5329032258064517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest"
      ],
      "metadata": {
        "id": "ggQoaaBYukDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF_tfidf = RandomForestClassifier()\n",
        "RF_tfidf.fit(X_train_tfidf, y_train)\n",
        "RF_tfidf_pred = RF_tfidf.predict(X_test_tfidf)\n",
        "print(f'accuracy: {accuracy_score(y_test, RF_tfidf_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uhCGxmcrl5g",
        "outputId": "bb315567-6153-41c5-d842-fc2ba7b800e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8903225806451613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_sim = top10(tfidf_text.toarray(), 5)\n",
        "for top in top_sim:\n",
        "  print(df['text'][top['id']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgsZdXRhurod",
        "outputId": "48febd8b-56fe-4b56-c1ef-52a20d59677f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi Guys\n",
            " popping into a store\n",
            " SURE NO PROB. ILABYU TOO  \n",
            "Sup guys? :D\n",
            "This week Marilyn pops by and get's down and dirty  happy  Cum see!\n",
            "Don't do that unhappy \n",
            "Her back unhappy  \n",
            "Same unhappy \n",
            "Her back unhappy  .1\n",
            "same unhappy \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doc2Vec"
      ],
      "metadata": {
        "id": "JdbYZ3qzYO5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cores = multiprocessing.cpu_count()\n",
        "text = [' '.join(doc) for doc in preprocessing_doc(df['text'])]\n",
        "X_train_d2v, X_test_d2v, y_train, y_test = train_test_split(text, df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])"
      ],
      "metadata": {
        "id": "n1kE7V9vy2FR"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_corpus = np.empty(len(X_train_d2v), dtype=object)\n",
        "for i, text in enumerate(X_train_d2v):\n",
        "  tagged_doc = TaggedDocument(text, [i])\n",
        "  training_corpus[i] = tagged_doc\n",
        "model_d2v = Doc2Vec(vector_size=100, min_count=2, worker=num_cores, epochs=10)\n",
        "model_d2v.build_vocab(training_corpus)\n",
        "model_d2v.train(training_corpus, total_examples=model_d2v.corpus_count, epochs=model_d2v.epochs)"
      ],
      "metadata": {
        "id": "kiVwHr8BY0_6"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_train = model_d2v.docvecs.vectors_docs\n",
        "d2v_test = [model_d2v.infer_vector(doc) for doc in X_test_d2v]"
      ],
      "metadata": {
        "id": "KxcyXCxYa7es"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "b2F3SOcxeQ7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KNN_d2v = KNeighborsClassifier()\n",
        "KNN_d2v.fit(d2v_train, y_train)\n",
        "KNN_d2v_pred = KNN_d2v.predict(d2v_test)\n",
        "print(f'accuracy: {accuracy_score(y_test, KNN_d2v_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G32_vFOrdo-N",
        "outputId": "1d00654f-630e-4926-8c98-7ea8ff6d201e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5561290322580645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "YDDwe2SJh4Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF_d2v = RandomForestClassifier()\n",
        "RF_d2v.fit(d2v_train, y_train)\n",
        "RF_d2v_pred = RF_d2v.predict(d2v_test)\n",
        "print(f'accuracy: {accuracy_score(y_test, RF_d2v_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp4oxeIkgue_",
        "outputId": "e08dfe1b-d918-467b-e1ce-ea2fb0345b8f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5574193548387096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## most similar"
      ],
      "metadata": {
        "id": "mMrFmpL5lQ7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['text'][0], '\\n')\n",
        "top_d2v = model_d2v.docvecs.most_similar([model_d2v.infer_vector(preprocess_string(df['text'][0]))])\n",
        "for top in top_d2v:\n",
        "  print(training_corpus[top[0]][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3rxaygBiAlt",
        "outputId": "d7b5c9ca-5ed0-4966-e906-a479ddeb75d5"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How unhappy  some dogs like it though \n",
            "\n",
            "im done trying take men seriously happy\n",
            "$ 10 also free postage . wish seller yanan yeo one . unhappy\n",
            "puta know sorry enough pero sorry padin unhappy\n",
            "they're like 90 calories per piece unhappy\n",
            "nice outside stuck school day unhappy\n",
            "help made sent starters p1q3 . open suggestions improve happy\n",
            "\n",
            "\n",
            "happy birthday katrika miss though unhappy miss group haih anyway\n",
            "india readies $ 5bn credit line backup .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "nxAH8ArTpJPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'].values, df['sentiment'].values, test_size=0.2, random_state=42) "
      ],
      "metadata": {
        "id": "t2kFfdaLmgMu"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_vocab = 500000\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "wordidx=tokenizer.word_index"
      ],
      "metadata": {
        "id": "hk1bzxK5pQgw"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "87FpjbNzpYEZ"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_train = pad_sequences(train_seq)\n",
        "T = pad_train.shape[1]\n",
        "pad_test=pad_sequences(test_seq,maxlen=T)"
      ],
      "metadata": {
        "id": "puv-di3JpdkA"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense,GlobalMaxPool1D,Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "M = 100\n",
        "D = 20\n",
        "i = Input(shape=(T, ))\n",
        "x = Embedding(max_vocab+1,D)(i)\n",
        "x = LSTM(M, return_sequences=True)(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(1, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YIKs_IKprvl",
        "outputId": "047fa28a-cf30-440c-c064-c42adae73113"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 30)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 30, 20)            10000020  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 30, 100)           48400     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 100)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                3232      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,051,685\n",
            "Trainable params: 10,051,685\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "r = model.fit(pad_train, y_train, validation_data=(pad_test, y_test), epochs=100, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebFYa8tap2TQ",
        "outputId": "8aca005e-c664-4510-ece5-369f3e9459f8"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "49/49 [==============================] - 12s 148ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 2/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 3/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 4/100\n",
            "49/49 [==============================] - 6s 131ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 5/100\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 6/100\n",
            "49/49 [==============================] - 6s 131ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 7/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 8/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 9/100\n",
            "49/49 [==============================] - 6s 131ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 10/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 11/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 12/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 13/100\n",
            "49/49 [==============================] - 7s 136ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 14/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 15/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 16/100\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 17/100\n",
            "49/49 [==============================] - 7s 139ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 18/100\n",
            "49/49 [==============================] - 7s 140ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 19/100\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 20/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 21/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 22/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 23/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 24/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 25/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 26/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 27/100\n",
            "49/49 [==============================] - 7s 136ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 28/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 29/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 30/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 31/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 32/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 33/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 34/100\n",
            "49/49 [==============================] - 7s 149ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 35/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 36/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 37/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 38/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 39/100\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 40/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 41/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 42/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 43/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 44/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 45/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 46/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 47/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 48/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 49/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 50/100\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 51/100\n",
            "49/49 [==============================] - 7s 150ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 52/100\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 53/100\n",
            "49/49 [==============================] - 6s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 54/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 55/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 56/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 57/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 58/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 59/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 60/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 61/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 62/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 63/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 64/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 65/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 66/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 67/100\n",
            "49/49 [==============================] - 7s 148ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 68/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 69/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 70/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 71/100\n",
            "49/49 [==============================] - 6s 131ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 72/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 73/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 74/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 75/100\n",
            "49/49 [==============================] - 6s 131ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 76/100\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 77/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 78/100\n",
            "49/49 [==============================] - 6s 131ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 79/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 80/100\n",
            "49/49 [==============================] - 7s 136ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 81/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 82/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 83/100\n",
            "49/49 [==============================] - 7s 136ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 84/100\n",
            "49/49 [==============================] - 7s 149ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 85/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 86/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 87/100\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 88/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 89/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 90/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 91/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 92/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 93/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 94/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 95/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 96/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 97/100\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 98/100\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 99/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n",
            "Epoch 100/100\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.0000e+00 - accuracy: 0.3063 - val_loss: 0.0000e+00 - val_accuracy: 0.3058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FOq0tpwZtVAa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}